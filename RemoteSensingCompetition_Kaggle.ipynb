{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNR638-RemoteSensing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT-QaGpfw_gs"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch\n",
        "import csv\n",
        "import os\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "resume_weights = \"/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/checkpointcrazy6.pth.tar\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI8xlyJMTptv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FAQsh-R04ho"
      },
      "source": [
        "# Import Python libraries  \n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image\n",
        "\n",
        "# Import PyTorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C3-a1hixLda"
      },
      "source": [
        "tforms = transforms.Compose([transforms.Grayscale(3),  \n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Normalize([0.458, 0.456, 0.406],\n",
        "                                                [0.229, 0.224, 0.225])])\n",
        "test_transform = transforms.Compose([\n",
        "       \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.458, 0.456, 0.406],\n",
        "                                                [0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biVoDEUtVPao"
      },
      "source": [
        "DEVICE_IDS = [0, 1, 2, 3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64A8sqMqvJN6"
      },
      "source": [
        "from torchvision import datasets\n",
        "#dataFromFolders = datasets.ImageFolder(root='/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/train',transform = tforms)\n",
        "\n",
        "\n",
        "import PIL\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "#len(dataFromFolders)\n",
        "transforms2 = torchvision.transforms.Compose([\n",
        "    #torchvision.transforms.Resize((224,224)),\n",
        "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
        "    transforms.Grayscale(3),  \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.458, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "\n",
        "#dataFromFolders2 = torchvision.datasets.ImageFolder('/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/train', transform=transforms)\n",
        "# len(dataFromFolders2)\n",
        "#dataFromFolders = torch.utils.data.ConcatDataset([dataFromFolders,dataFromFolders2])\n",
        "# len(increased_dataset)\n",
        "dataFromFolders = datasets.ImageFolder(root='/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/train',transform = transforms2)\n",
        "\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "batch_size = 16\n",
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "dataset_size = len(dataFromFolders)\n",
        "print(len(dataFromFolders))\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "folderloader = DataLoader(dataFromFolders, batch_size=batch_size,sampler=train_sampler)\n",
        "print(folderloader)\n",
        "images, labels = iter(folderloader).next()\n",
        "\n",
        "#dataFromFolders_valid = datasets.ImageFolder(root='/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/train',transform = tforms)\n",
        "folderloader_valid = DataLoader(dataFromFolders, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "dataFromFolders_test = datasets.ImageFolder(root='/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/test_set',transform = test_transform)\n",
        "folderloader_test = DataLoader(dataFromFolders_test,batch_size=1)\n",
        "\n",
        "print(labels.size())\n",
        "print(images.size())\n",
        "print(len(folderloader))\n",
        "print(len(folderloader_valid))\n",
        "print(len(folderloader_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_HLEnl9OlHZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h13IScSJmfTV"
      },
      "source": [
        "# images, labels = iter(folderloader).next()\n",
        "# #print(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYiW019Kn6G1"
      },
      "source": [
        "class AlexNet2(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural network model consisting of layers propsed by AlexNet paper.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=7):\n",
        "        \"\"\"\n",
        "        Define and allocate layers for this neural net.\n",
        "        Args:\n",
        "            num_classes (int): number of classes to predict with this model\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # input size should be : (b x 3 x 227 x 227)  here (bx3x256x256)\n",
        "        # The image in the original paper states that width and height are 224 pixels, but\n",
        "        # the dimensions after first convolution layer do not lead to 55 x 55.\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 96 x 55 x 55)   (bx96x62x62)\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            #nn.Dropout(p=0.2, inplace=True),\n",
        "            #nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 96 x 27 x 27)   (bx96x30x30)\n",
        "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 256 x 27 x 27)     (bx256x30x30)\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            #nn.Dropout(p=0.2, inplace=True),\n",
        "            #nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 256 x 13 x 13)  (bx256x14x14)\n",
        "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 384 x 13 x 13)  (bx512x14x14)\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(p=0.2, inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 96 x 27 x 27)   (bx96x30x30)\n",
        "            nn.Conv2d(256,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 384 x 13 x 13)  (bx512x14x14)\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(p=0.2, inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 96 x 27 x 27)   (bx96x30x30)\n",
        "            # nn.Conv2d(512,512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 256 x 13 x 13)  (bx512x14x14)\n",
        "            # nn.ReLU(True),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            # nn.Dropout(p=0.2, inplace=True),\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 256 x 6 x 6)   (bx256x6x6)\n",
        "        )\n",
        "        # classifier is just a name for linear layers\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5, inplace=True),\n",
        "            nn.Linear(in_features=(256 * 6 * 6), out_features=512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(p=0.5, inplace=True),\n",
        "            # nn.Linear(in_features=4096, out_features=4096),\n",
        "            #nn.ReLU(True),\n",
        "            nn.Linear(in_features=512, out_features=num_classes),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "        #self.init_bias()  # initialize bias\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def init_bias(self):\n",
        "        for layer in self.net:\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
        "                nn.init.constant_(layer.bias, 0)\n",
        "        # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\n",
        "        nn.init.constant_(self.net[4].bias, 1)\n",
        "        nn.init.constant_(self.net[10].bias, 1)\n",
        "        nn.init.constant_(self.net[12].bias, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Pass the input through the net.\n",
        "        Args:\n",
        "            x (Tensor): input tensor\n",
        "        Returns:\n",
        "            output (Tensor): output tensor\n",
        "        \"\"\"\n",
        "        x = self.net(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        #x = self.classifier(x)\n",
        "        #x = x.view(-1, 256 * 6 * 6)  # reduce the dimensions for linear layer input\n",
        "        return self.classifier(x)\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRnFT9LuLfk7"
      },
      "source": [
        "best_accuracy = torch.FloatTensor([0])\n",
        "start_epoch = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1YpsOiPwptt"
      },
      "source": [
        "# model = models.vgg11(pretrained=True)\n",
        "# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# # model.to(device)\n",
        "# display(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eduJAbCGXCPe"
      },
      "source": [
        "torch.cuda.device_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KMMyDg-fFGY"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "model = AlexNet2(num_classes=7).to(device)\n",
        "#model = torch.nn.parallel.DataParallel(model, device_ids=DEVICE_IDS)\n",
        "display(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxt6Gzba0vwf"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2byeJwx0yvy"
      },
      "source": [
        "\n",
        "# Parameters \n",
        "in_features = 256*7*7\n",
        "out_categories = 7\n",
        "layer_1 = 512\n",
        "layer_2 = 512\n",
        "# Build classifier\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    #('dropout1', nn.Dropout(0.5)),\n",
        "    ('fc1', nn.Linear(in_features, layer_1)),\n",
        "    ('relu', nn.ReLU(True)),\n",
        "    ('dropout2', nn.Dropout(0.5)),\n",
        "    ('fc2', nn.Linear(layer_1, layer_2)),\n",
        "    ('relu', nn.ReLU(True)),\n",
        "    ('dropout3', nn.Dropout(0.5)),    \n",
        "    ('fc3', nn.Linear(layer_2, out_categories)),\n",
        "    ('output', nn.LogSoftmax(dim=1))\n",
        "    ]))\n",
        "\n",
        "# Assign new classifier to VGG-11 architecture \n",
        "model.classifier = classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSFJnEEk01dr"
      },
      "source": [
        "\n",
        "# Instantiate loss function\n",
        "loss_function = nn.NLLLoss()\n",
        "\n",
        "# Instantiate optimization algorithm \n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# Enable CUDA: use GPUs for model computation\n",
        "if torch.cuda.is_available():\n",
        "    print('a')\n",
        "    model.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr7TBOzb1BEI"
      },
      "source": [
        "# Epochs: number of iterations over the entire training dataset\n",
        "epochs = 50\n",
        "# Number of iterations between printing loss and accuracy \n",
        "print_steps = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ER3bI178MGg"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLttiVIutXW1"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUr1RKmESlUh"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sPtOJLb5WVw"
      },
      "source": [
        "# Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAZujqh-5V1H"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename = \"/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/checkpointcrazy6.pth.tar\"):\n",
        "    if is_best:\n",
        "        best_accuracy = state['best_accuracy']\n",
        "        print (\"=> Saving a new best with {:.4}% validation accuracy\".format(100 * best_accuracy.numpy()[0]))\n",
        "        torch.save(state, filename)  # save checkpoint\n",
        "    else:\n",
        "        print (\"=> Validation Accuracy did not improve\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ox5S30c5ZY2"
      },
      "source": [
        "if os.path.isfile(resume_weights):\n",
        "    print(\"=> loading checkpoint '{}' ...\".format(resume_weights))\n",
        "    if torch.cuda:\n",
        "       checkpoint = torch.load(resume_weights)\n",
        "    else:\n",
        "       checkpoint = torch.load(resume_weights,\n",
        "                               map_location=lambda storage,\n",
        "                               loc: storage)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_accuracy = checkpoint['best_accuracy']\n",
        "    print('=> loaded checkpoint {} (trained for {} epochs) with {:.4}% validation accuracy'.format(resume_weights,\n",
        "        checkpoint['epoch'],100 * best_accuracy.numpy()[0]))\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "else:print(\"no\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0elE66t5psv"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUPFUOUQ1DJ9",
        "outputId": "4094717d-ba52-498c-968e-ff5ef130f82a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Initialize steps\n",
        "step = 0\n",
        "\n",
        "# Iterate over number of epochs\n",
        "for e in range(epochs):\n",
        "    running_loss = 0 \n",
        "\n",
        "    # Iterate over the entire training dataset\n",
        "    # one batch per iteration \n",
        "    for input_images, labels in folderloader:\n",
        "        step += 1     \n",
        "        \n",
        "        # Enable CUDA: use GPUs for model computation\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = input_images.to('cuda'), labels.to('cuda')   \n",
        "        else:\n",
        "            inputs, labels = input_images, labels\n",
        "        \n",
        "        # Clear the gradients of all optimized tensors\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model.forward(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "     \n",
        "        #print(predicted,labels)\n",
        "        validation_correct = 0\n",
        "        validation_total = 0\n",
        "\n",
        "        training_correct = 0\n",
        "        training_total = 0        \n",
        "\n",
        "        # no_grad() prevents tracking history (and using memory)\n",
        "        with torch.no_grad(): \n",
        "            \n",
        "            # Iterate over the entire validation dataset\n",
        "            for input_images3, labels3 in folderloader:\n",
        "                \n",
        "                # Enable CUDA: use GPUs for model computation\n",
        "                if torch.cuda.is_available():\n",
        "                    input_images3, labels3 = input_images3.to('cuda'), labels3.to('cuda')\n",
        "                \n",
        "                \n",
        "                # Make predictions \n",
        "                outputs3 = model(input_images3)\n",
        "                _, predicted3 = torch.max(outputs3.data, 1)\n",
        "                #print(predicted2,labels2)\n",
        "                \n",
        "                # Count total and correct predictions\n",
        "                training_total += labels3.size(0)\n",
        "                training_correct += (predicted3 == labels3).sum().item()   \n",
        "\n",
        "        with torch.no_grad(): \n",
        "            \n",
        "            # Iterate over the entire validation dataset\n",
        "            for input_images2, labels2 in folderloader_valid:\n",
        "                \n",
        "                # Enable CUDA: use GPUs for model computation\n",
        "                if torch.cuda.is_available():\n",
        "                    input_images2, labels2 = input_images2.to('cuda'), labels2.to('cuda')\n",
        "                \n",
        "                # Make predictions \n",
        "                outputs2 = model(input_images2)\n",
        "                _, predicted2 = torch.max(outputs2.data, 1)\n",
        "                #print(predicted2,labels2)\n",
        "                \n",
        "                # Count total and correct predictions\n",
        "                validation_total += labels2.size(0)\n",
        "                validation_correct += (predicted2 == labels2).sum().item()\n",
        "        loss = loss_function(outputs, labels)\n",
        "        val_acc = validation_correct / validation_total\n",
        "        train_acc = training_correct / training_total\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Calculate and print running training loss\n",
        "        running_loss += loss.item()       \n",
        "        if step % print_steps == 0:\n",
        "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
        "                  \"| Loss: {:.4f}\".format(running_loss/print_steps),\n",
        "                  \"| Val Acc: {:.4f}\".format(val_acc),\n",
        "                  \"| Train Acc: {:.4f}\".format(train_acc),)\n",
        "            running_loss = 0\n",
        "    acc1 = torch.FloatTensor([val_acc])\n",
        "    is_best = bool(acc1.numpy() > best_accuracy.numpy())\n",
        "    best_accuracy = torch.FloatTensor(max(acc1.numpy(), best_accuracy.numpy()))\n",
        "    save_checkpoint({\n",
        "        'epoch' : start_epoch + epochs,\n",
        "        'state_dict' : model.state_dict(),\n",
        "        'best_accuracy' : best_accuracy\n",
        "        }, is_best)\n",
        "        \n",
        "print('\\nCount of data batches seen:  {} \\n'.format(step))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/50...  | Loss: 0.3445 | Val Acc: 0.8661 | Train Acc: 0.8817\n",
            "Epoch: 1/50...  | Loss: 0.2020 | Val Acc: 0.8571 | Train Acc: 0.9576\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 2/50...  | Loss: 0.0359 | Val Acc: 0.8571 | Train Acc: 0.9643\n",
            "Epoch: 2/50...  | Loss: 0.1229 | Val Acc: 0.9018 | Train Acc: 0.9643\n",
            "Epoch: 2/50...  | Loss: 0.0854 | Val Acc: 0.9018 | Train Acc: 0.9754\n",
            "=> Saving a new best with 87.5% validation accuracy\n",
            "Epoch: 3/50...  | Loss: 0.0272 | Val Acc: 0.8661 | Train Acc: 0.9531\n",
            "Epoch: 3/50...  | Loss: 0.1257 | Val Acc: 0.8839 | Train Acc: 0.9710\n",
            "Epoch: 3/50...  | Loss: 0.0791 | Val Acc: 0.9107 | Train Acc: 0.9844\n",
            "=> Saving a new best with 92.86% validation accuracy\n",
            "Epoch: 4/50...  | Loss: 0.0459 | Val Acc: 0.9196 | Train Acc: 0.9688\n",
            "Epoch: 4/50...  | Loss: 0.1141 | Val Acc: 0.9196 | Train Acc: 0.9732\n",
            "Epoch: 4/50...  | Loss: 0.0661 | Val Acc: 0.9375 | Train Acc: 0.9754\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 5/50...  | Loss: 0.0488 | Val Acc: 0.9286 | Train Acc: 0.9710\n",
            "Epoch: 5/50...  | Loss: 0.0871 | Val Acc: 0.9107 | Train Acc: 0.9688\n",
            "Epoch: 5/50...  | Loss: 0.0672 | Val Acc: 0.9107 | Train Acc: 0.9888\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 6/50...  | Loss: 0.0578 | Val Acc: 0.9196 | Train Acc: 0.9955\n",
            "Epoch: 6/50...  | Loss: 0.0586 | Val Acc: 0.9286 | Train Acc: 0.9866\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 7/50...  | Loss: 0.0108 | Val Acc: 0.9286 | Train Acc: 0.9888\n",
            "Epoch: 7/50...  | Loss: 0.0588 | Val Acc: 0.9375 | Train Acc: 0.9888\n",
            "Epoch: 7/50...  | Loss: 0.0583 | Val Acc: 0.9375 | Train Acc: 0.9933\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 8/50...  | Loss: 0.0146 | Val Acc: 0.9018 | Train Acc: 0.9888\n",
            "Epoch: 8/50...  | Loss: 0.0554 | Val Acc: 0.9286 | Train Acc: 0.9955\n",
            "Epoch: 8/50...  | Loss: 0.0455 | Val Acc: 0.9196 | Train Acc: 0.9933\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 9/50...  | Loss: 0.0322 | Val Acc: 0.9375 | Train Acc: 0.9978\n",
            "Epoch: 9/50...  | Loss: 0.0354 | Val Acc: 0.9107 | Train Acc: 0.9866\n",
            "Epoch: 9/50...  | Loss: 0.0426 | Val Acc: 0.8929 | Train Acc: 0.9754\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 10/50...  | Loss: 0.0329 | Val Acc: 0.9375 | Train Acc: 0.9866\n",
            "Epoch: 10/50...  | Loss: 0.0524 | Val Acc: 0.9375 | Train Acc: 0.9978\n",
            "Epoch: 10/50...  | Loss: 0.0444 | Val Acc: 0.9286 | Train Acc: 0.9933\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 11/50...  | Loss: 0.0297 | Val Acc: 0.9196 | Train Acc: 0.9955\n",
            "Epoch: 11/50...  | Loss: 0.0359 | Val Acc: 0.9196 | Train Acc: 0.9955\n",
            "=> Saving a new best with 93.75% validation accuracy\n",
            "Epoch: 12/50...  | Loss: 0.0044 | Val Acc: 0.9196 | Train Acc: 0.9955\n",
            "Epoch: 12/50...  | Loss: 0.0356 | Val Acc: 0.9375 | Train Acc: 0.9955\n",
            "Epoch: 12/50...  | Loss: 0.0281 | Val Acc: 0.9196 | Train Acc: 0.9955\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 13/50...  | Loss: 0.0230 | Val Acc: 0.9286 | Train Acc: 0.9866\n",
            "Epoch: 13/50...  | Loss: 0.0393 | Val Acc: 0.9196 | Train Acc: 0.9933\n",
            "Epoch: 13/50...  | Loss: 0.0428 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 14/50...  | Loss: 0.0195 | Val Acc: 0.9018 | Train Acc: 0.9933\n",
            "Epoch: 14/50...  | Loss: 0.0459 | Val Acc: 0.9375 | Train Acc: 0.9955\n",
            "Epoch: 14/50...  | Loss: 0.0283 | Val Acc: 0.9286 | Train Acc: 0.9933\n",
            "=> Saving a new best with 94.64% validation accuracy\n",
            "Epoch: 15/50...  | Loss: 0.0220 | Val Acc: 0.9107 | Train Acc: 0.9955\n",
            "Epoch: 15/50...  | Loss: 0.0282 | Val Acc: 0.9286 | Train Acc: 0.9978\n",
            "Epoch: 15/50...  | Loss: 0.0242 | Val Acc: 0.9196 | Train Acc: 0.9955\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 16/50...  | Loss: 0.0474 | Val Acc: 0.9196 | Train Acc: 1.0000\n",
            "Epoch: 16/50...  | Loss: 0.0220 | Val Acc: 0.9107 | Train Acc: 0.9955\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 17/50...  | Loss: 0.0092 | Val Acc: 0.9196 | Train Acc: 1.0000\n",
            "Epoch: 17/50...  | Loss: 0.0280 | Val Acc: 0.9196 | Train Acc: 1.0000\n",
            "Epoch: 17/50...  | Loss: 0.0265 | Val Acc: 0.9196 | Train Acc: 0.9978\n",
            "=> Saving a new best with 95.54% validation accuracy\n",
            "Epoch: 18/50...  | Loss: 0.0112 | Val Acc: 0.9018 | Train Acc: 0.9955\n",
            "Epoch: 18/50...  | Loss: 0.0137 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 18/50...  | Loss: 0.0278 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 19/50...  | Loss: 0.0303 | Val Acc: 0.9375 | Train Acc: 0.9978\n",
            "Epoch: 19/50...  | Loss: 0.0385 | Val Acc: 0.9286 | Train Acc: 0.9955\n",
            "Epoch: 19/50...  | Loss: 0.0288 | Val Acc: 0.9196 | Train Acc: 0.9978\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 20/50...  | Loss: 0.0228 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 20/50...  | Loss: 0.0255 | Val Acc: 0.9196 | Train Acc: 1.0000\n",
            "Epoch: 20/50...  | Loss: 0.0210 | Val Acc: 0.8929 | Train Acc: 0.9933\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 21/50...  | Loss: 0.0224 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "Epoch: 21/50...  | Loss: 0.0238 | Val Acc: 0.9286 | Train Acc: 0.9933\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 22/50...  | Loss: 0.0027 | Val Acc: 0.9286 | Train Acc: 0.9955\n",
            "Epoch: 22/50...  | Loss: 0.0255 | Val Acc: 0.9375 | Train Acc: 0.9978\n",
            "Epoch: 22/50...  | Loss: 0.0252 | Val Acc: 0.9196 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 23/50...  | Loss: 0.0075 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 23/50...  | Loss: 0.0203 | Val Acc: 0.9464 | Train Acc: 0.9955\n",
            "Epoch: 23/50...  | Loss: 0.0202 | Val Acc: 0.9286 | Train Acc: 0.9978\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 24/50...  | Loss: 0.0217 | Val Acc: 0.9196 | Train Acc: 0.9978\n",
            "Epoch: 24/50...  | Loss: 0.0099 | Val Acc: 0.9286 | Train Acc: 0.9955\n",
            "Epoch: 24/50...  | Loss: 0.0180 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 25/50...  | Loss: 0.0119 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 25/50...  | Loss: 0.0190 | Val Acc: 0.9375 | Train Acc: 0.9978\n",
            "Epoch: 25/50...  | Loss: 0.0139 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 26/50...  | Loss: 0.0120 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 26/50...  | Loss: 0.0108 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 27/50...  | Loss: 0.0017 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 27/50...  | Loss: 0.0176 | Val Acc: 0.9375 | Train Acc: 0.9955\n",
            "Epoch: 27/50...  | Loss: 0.0163 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 28/50...  | Loss: 0.0032 | Val Acc: 0.9196 | Train Acc: 0.9955\n",
            "Epoch: 28/50...  | Loss: 0.0150 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 28/50...  | Loss: 0.0116 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 29/50...  | Loss: 0.0061 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "Epoch: 29/50...  | Loss: 0.0089 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 29/50...  | Loss: 0.0156 | Val Acc: 0.9196 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 30/50...  | Loss: 0.0195 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 30/50...  | Loss: 0.0091 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "Epoch: 30/50...  | Loss: 0.0123 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 31/50...  | Loss: 0.0059 | Val Acc: 0.9286 | Train Acc: 0.9978\n",
            "Epoch: 31/50...  | Loss: 0.0072 | Val Acc: 0.9464 | Train Acc: 0.9978\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 32/50...  | Loss: 0.0014 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 32/50...  | Loss: 0.0108 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 32/50...  | Loss: 0.0093 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 33/50...  | Loss: 0.0042 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 33/50...  | Loss: 0.0097 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "Epoch: 33/50...  | Loss: 0.0086 | Val Acc: 0.9643 | Train Acc: 0.9978\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 34/50...  | Loss: 0.0035 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 34/50...  | Loss: 0.0098 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 34/50...  | Loss: 0.0085 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 35/50...  | Loss: 0.0051 | Val Acc: 0.9196 | Train Acc: 0.9978\n",
            "Epoch: 35/50...  | Loss: 0.0079 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 35/50...  | Loss: 0.0042 | Val Acc: 0.9018 | Train Acc: 0.9978\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 36/50...  | Loss: 0.0064 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "Epoch: 36/50...  | Loss: 0.0072 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 37/50...  | Loss: 0.0026 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 37/50...  | Loss: 0.0091 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 37/50...  | Loss: 0.0060 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 38/50...  | Loss: 0.0016 | Val Acc: 0.9196 | Train Acc: 1.0000\n",
            "Epoch: 38/50...  | Loss: 0.0071 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "Epoch: 38/50...  | Loss: 0.0069 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 39/50...  | Loss: 0.0038 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 39/50...  | Loss: 0.0067 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 39/50...  | Loss: 0.0084 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 40/50...  | Loss: 0.0038 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 40/50...  | Loss: 0.0093 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "Epoch: 40/50...  | Loss: 0.0037 | Val Acc: 0.9464 | Train Acc: 0.9978\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 41/50...  | Loss: 0.0038 | Val Acc: 0.9554 | Train Acc: 1.0000\n",
            "Epoch: 41/50...  | Loss: 0.0045 | Val Acc: 0.9375 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 42/50...  | Loss: 0.0013 | Val Acc: 0.9286 | Train Acc: 1.0000\n",
            "Epoch: 42/50...  | Loss: 0.0072 | Val Acc: 0.9286 | Train Acc: 0.9978\n",
            "Epoch: 42/50...  | Loss: 0.0114 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 43/50...  | Loss: 0.0025 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "Epoch: 43/50...  | Loss: 0.0100 | Val Acc: 0.9464 | Train Acc: 1.0000\n",
            "Epoch: 43/50...  | Loss: 0.0136 | Val Acc: 0.9196 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 44/50...  | Loss: 0.0087 | Val Acc: 0.9196 | Train Acc: 0.9978\n",
            "Epoch: 44/50...  | Loss: 0.0127 | Val Acc: 0.9107 | Train Acc: 0.9955\n",
            "Epoch: 44/50...  | Loss: 0.0059 | Val Acc: 0.9196 | Train Acc: 1.0000\n",
            "=> Validation Accuracy did not improve\n",
            "Epoch: 45/50...  | Loss: 0.0218 | Val Acc: 0.9107 | Train Acc: 0.9955\n",
            "Epoch: 45/50...  | Loss: 0.0213 | Val Acc: 0.9554 | Train Acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GeclCPrhD5u"
      },
      "source": [
        "# Validation and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZSKvM6B1HAR"
      },
      "source": [
        "validation_correct = 0\n",
        "validation_total = 0\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "# no_grad() prevents tracking history (and using memory)\n",
        "model.eval()\n",
        "with torch.no_grad(): \n",
        "    \n",
        "    # Iterate over the entire validation dataset\n",
        "    for input_images, labels in folderloader_valid:\n",
        "        \n",
        "        # Enable CUDA: use GPUs for model computation\n",
        "        if torch.cuda.is_available():\n",
        "            input_images, labels = input_images.to('cuda'), labels.to('cuda')\n",
        "        \n",
        "        # Make predictions \n",
        "        outputs = model(input_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        print(input_images.size(),labels)\n",
        "        \n",
        "        # Count total and correct predictions\n",
        "        validation_total += labels.size(0)\n",
        "        validation_correct += (predicted == labels).sum().item()\n",
        "# Print validation accuracy\n",
        "print('Validation accuracy ({0:d} validation images): {1:.1%}'\n",
        "      .format(validation_total, validation_correct / validation_total))        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMWRtqSEym1L"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "import glob\n",
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/test_set\"\n",
        "dataFromFolders_test = ImageFolderWithPaths(root='/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/test_set',transform = test_transform)\n",
        "folderloader_test = DataLoader(dataFromFolders_test,batch_size=1)\n",
        "model.eval()\n",
        "final=[]\n",
        "with torch.no_grad(): \n",
        "    for input_images, labels, paths in folderloader_test:\n",
        "        if torch.cuda.is_available():\n",
        "            input_images, labels = input_images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        outputs = model(input_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        final.append(predicted.cpu().numpy()[0])\n",
        "\n",
        "my_dict = {0:1, 1:2, 2:3, 3:7, 4:4, 5:6, 6:5}\n",
        "answers = np.vectorize(my_dict.get)(final).tolist()\n",
        "answers = [str(x).strip(' ') for x in answers]\n",
        "answers = list(map(int, answers)) \n",
        "#print(answers)\n",
        "mypath = '/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/test_set'\n",
        "fileslist = []\n",
        "for root, directories, files in os.walk(mypath, topdown=False):\n",
        "    #print(files)\n",
        "    for name in files:\n",
        "        #print(name);\n",
        "        if name[4:] == '.jpg':\n",
        "            fileslist.append(int(name[:4]))\n",
        "fileslist = np.sort(fileslist)\n",
        "#print(fileslist)\n",
        "arr1 = np.array(fileslist)\n",
        "arr2 = np.array(answers)\n",
        "b = np.stack((arr1,arr2), axis=1)\n",
        "\n",
        "b = [[x for x in y if x != ''] for y in b]\n",
        "print(b)\n",
        "np.savetxt(\"foo.csv\", b, delimiter=',', header=\"ImageID,Label\", fmt='%1d',comments='')\n",
        "# 1 - Basketball court 2 - Beach 3 - Forest 4 - Railway \n",
        "# 5 - Tennis court 6 - Water pool 7 - Others      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7sQ8Gekynot"
      },
      "source": [
        "# waste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg_3hLBTaFiz"
      },
      "source": [
        "dataiter = iter(folderloader_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOXSmTrjZDHq"
      },
      "source": [
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# show images\n",
        "matplotlib_imshow(img_grid, one_channel=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sym0H5y5eDg4"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "\n",
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path\n",
        "\n",
        "# EXAMPLE USAGE:\n",
        "# instantiate the dataset and dataloader\n",
        "data_dir = \"/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/test_set\"\n",
        "dataset = ImageFolderWithPaths(data_dir,transform = test_transform) # our custom dataset\n",
        "dataloader = DataLoader(dataset)\n",
        "final=[]\n",
        "# iterate over data\n",
        "for input_images, labels, paths in dataloader:\n",
        "    # use the above variables freely\n",
        "    #print( paths)\n",
        "    if torch.cuda.is_available():\n",
        "            input_images, labels = input_images.to('cuda'), labels.to('cuda')\n",
        "            #print(labels)\n",
        "        \n",
        "    # Make predictions \n",
        "    print((input_images).size())\n",
        "    import tensorflow as tf\n",
        "    import numpy as np\n",
        "\n",
        "    # x = tf.placeholder(tf.float32, (None, 3, 256, 256))\n",
        "\n",
        "    # reduced = tf.expand_dims(tf.reduce_mean(x, axis=1), 1)\n",
        "    # reduced = tf.expand_dims(tf.reduce_mean(reduced, axis=2), 2)\n",
        "\n",
        "    # data = input_images\n",
        "\n",
        "    # with tf.Session() as sess:\n",
        "    #     evaled = reduced.eval({x:data})\n",
        "    #     print(evaled.shape) # (16, 1, 1, 64)\n",
        "    outputs = model(input_images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    sample_fname, _ = folderloader_test.dataset.samples[i]\n",
        "    #print(sample_fname)\n",
        "    #print(predicted)\n",
        "    final += (predicted.cpu().data.numpy().tolist())\n",
        "my_dict = {0:1, 1:2, 2:3, 3:7, 4:4, 5:6, 6:5}\n",
        "answers = np.vectorize(my_dict.get)(final).tolist()\n",
        "answers = [str(x).strip(' ') for x in answers]\n",
        "answers = list(map(int, answers)) \n",
        "print(answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AdyOaEx6NiY"
      },
      "source": [
        "final = []\n",
        "# seed = 1\n",
        "# torch.manual_seed(seed)\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.cuda.manual_seed_all(seed)\n",
        "print(dataFromFolders_test.imgs)\n",
        "with torch.no_grad(): \n",
        "    \n",
        "    # Iterate over the entire validation dataset\n",
        "    for i, (images, labels) in enumerate(folderloader_test, 0):\n",
        "    #for input_images, labels in folderloader_test:\n",
        "        \n",
        "        # Enable CUDA: use GPUs for model computation\n",
        "        if torch.cuda.is_available():\n",
        "            input_images, labels = input_images.to('cuda'), labels.to('cuda')\n",
        "            print(labels)\n",
        "        \n",
        "        # Make predictions \n",
        "        outputs = model(input_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        sample_fname, _ = folderloader_test.dataset.samples[i]\n",
        "        #print(sample_fname)\n",
        "        print(predicted)\n",
        "        final += (predicted.cpu().data.numpy().tolist())\n",
        "my_dict = {0:1, 1:2, 2:3, 3:7, 4:4, 5:6, 6:5}\n",
        "answers = np.vectorize(my_dict.get)(final).tolist()\n",
        "answers = [str(x).strip(' ') for x in answers]\n",
        "answers = list(map(int, answers)) \n",
        "print(answers)\n",
        "#print(final)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnt7MIOMS1Td"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "import glob\n",
        "mypath = '/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/test_set'\n",
        "# for file_name in glob.iglob('/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/test_set/**/*', recursive=True):\n",
        "#   print(file_name)\n",
        "fileslist = []\n",
        "for root, directories, files in os.walk(mypath, topdown=False):\n",
        "\tfor name in files:\n",
        "\t\tfileslist.append(int(name[:4]))\n",
        "fileslist = np.sort(fileslist)\n",
        "#print(fileslist)\n",
        "arr1 = np.array(fileslist)\n",
        "arr2 = np.array(answers)\n",
        "b = np.stack((arr1,arr2), axis=1)\n",
        "\n",
        "b = [[x for x in y if x != ''] for y in b]\n",
        "print(b)\n",
        "np.savetxt(\"foo.csv\", b, delimiter=',', header=\"ImageID,Label\", fmt='%1d',comments='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aus6GHCW0NL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}