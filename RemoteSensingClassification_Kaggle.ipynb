{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code_180100088.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT-QaGpfw_gs"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch\n",
        "import csv\n",
        "import os\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "resume_weights = \"checkpointcrazy9.pth.tar\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI8xlyJMTptv",
        "outputId": "86e89afe-6eae-456b-e3ea-fe87182d6f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EN_lhENebpw"
      },
      "source": [
        "Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8dJ0lpTdVVx"
      },
      "source": [
        "dir_test = '/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/test_set'\n",
        "dir_data = '/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FAQsh-R04ho"
      },
      "source": [
        "# Import Python libraries  \n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image\n",
        "\n",
        "# Import PyTorch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C3-a1hixLda"
      },
      "source": [
        "tforms = transforms.Compose([transforms.Grayscale(3),  \n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Normalize([0.458, 0.456, 0.406],\n",
        "                                                [0.229, 0.224, 0.225])])\n",
        "test_transform = transforms.Compose([\n",
        "       \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.458, 0.456, 0.406],\n",
        "                                                [0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64A8sqMqvJN6",
        "outputId": "9a3c59f9-1157-4a5a-ff43-33adf428b1ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from torchvision import datasets\n",
        "#dataFromFolders = datasets.ImageFolder(root=dir_data,transform = tforms)\n",
        "\n",
        "\n",
        "import PIL\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "#len(dataFromFolders)\n",
        "transforms2 = torchvision.transforms.Compose([\n",
        "    #torchvision.transforms.Resize((224,224)),\n",
        "    torchvision.transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
        "    transforms.Grayscale(3),  \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.458, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
        "\n",
        "#dataFromFolders2 = torchvision.datasets.ImageFolder(dir_data, transform=transforms)\n",
        "# len(dataFromFolders2)\n",
        "#dataFromFolders = torch.utils.data.ConcatDataset([dataFromFolders,dataFromFolders2])\n",
        "# len(increased_dataset)\n",
        "dataFromFolders = datasets.ImageFolder(root=dir_data,transform = transforms2)\n",
        "\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "batch_size = 32\n",
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "dataset_size = len(dataFromFolders)\n",
        "print(len(dataFromFolders))\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "folderloader = DataLoader(dataFromFolders, batch_size=batch_size,sampler=train_sampler)\n",
        "print(folderloader)\n",
        "images, labels = iter(folderloader).next()\n",
        "\n",
        "#dataFromFolders_valid = datasets.ImageFolder(root=dir_data,transform = tforms)\n",
        "folderloader_valid = DataLoader(dataFromFolders, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "dataFromFolders_test = datasets.ImageFolder(root=dir_test,transform = test_transform)\n",
        "folderloader_test = DataLoader(dataFromFolders_test,batch_size=1)\n",
        "\n",
        "print(labels.size())\n",
        "print(images.size())\n",
        "print(len(folderloader))\n",
        "print(len(folderloader_valid))\n",
        "print(len(folderloader_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "560\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7f4a4391f048>\n",
            "torch.Size([32])\n",
            "torch.Size([32, 3, 256, 256])\n",
            "14\n",
            "4\n",
            "95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_HLEnl9OlHZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h13IScSJmfTV"
      },
      "source": [
        "# images, labels = iter(folderloader).next()\n",
        "# #print(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYiW019Kn6G1"
      },
      "source": [
        "class net(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural network model consisting of layers propsed by AlexNet paper.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=7):\n",
        "        \"\"\"\n",
        "        Define and allocate layers for this neural net.\n",
        "        Args:\n",
        "            num_classes (int): number of classes to predict with this model\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # input size should be : (b x 3 x 227 x 227)  here (bx3x256x256)\n",
        "        # The image in the original paper states that width and height are 224 pixels, but\n",
        "        # the dimensions after first convolution layer do not lead to 55 x 55.\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 96 x 55 x 55)   (bx96x62x62)\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm2d(64),\n",
        "            #nn.Dropout(p=0.2, inplace=True),\n",
        "            #nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),  # section 3.3\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 96 x 27 x 27)   (bx96x30x30)\n",
        "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 256 x 27 x 27)     (bx256x30x30)\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm2d(128),\n",
        "            #nn.Dropout(p=0.2, inplace=True),\n",
        "            #nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 256 x 13 x 13)  (bx256x14x14)\n",
        "            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 384 x 13 x 13)  (bx512x14x14)\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(p=0.2, inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 96 x 27 x 27)   (bx96x30x30)\n",
        "            nn.Conv2d(256,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 384 x 13 x 13)  (bx512x14x14)\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(p=0.2, inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 96 x 27 x 27)   (bx96x30x30)\n",
        "            nn.Conv2d(256,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),  # (b x 256 x 13 x 13)  (bx512x14x14)\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Dropout(p=0.2, inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),  # (b x 256 x 6 x 6)   (bx256x6x6)\n",
        "        )\n",
        "        # classifier is just a name for linear layers\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5, inplace=True),\n",
        "            nn.Linear(in_features=(256 * 6 * 6), out_features=512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(p=0.5, inplace=True),\n",
        "            # nn.Linear(in_features=4096, out_features=4096),\n",
        "            #nn.ReLU(True),\n",
        "            nn.Linear(in_features=512, out_features=num_classes),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "        #self.init_bias()  # initialize bias\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def init_bias(self):\n",
        "        for layer in self.net:\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
        "                nn.init.constant_(layer.bias, 0)\n",
        "        # original paper = 1 for Conv2d layers 2nd, 4th, and 5th conv layers\n",
        "        nn.init.constant_(self.net[4].bias, 1)\n",
        "        nn.init.constant_(self.net[10].bias, 1)\n",
        "        nn.init.constant_(self.net[12].bias, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Pass the input through the net.\n",
        "        Args:\n",
        "            x (Tensor): input tensor\n",
        "        Returns:\n",
        "            output (Tensor): output tensor\n",
        "        \"\"\"\n",
        "        x = self.net(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        #x = self.classifier(x)\n",
        "        #x = x.view(-1, 256 * 6 * 6)  # reduce the dimensions for linear layer input\n",
        "        return self.classifier(x)\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRnFT9LuLfk7"
      },
      "source": [
        "best_accuracy = torch.FloatTensor([0])\n",
        "start_epoch = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1YpsOiPwptt"
      },
      "source": [
        "# model = models.vgg11(pretrained=True)\n",
        "# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# # model.to(device)\n",
        "# display(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eduJAbCGXCPe",
        "outputId": "7f6cc25d-2d2b-4d0b-f65e-b39f9c3b6779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.device_count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KMMyDg-fFGY",
        "outputId": "741823f3-f23f-41cf-e620-36b0cc1ec69d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "model = net(num_classes=7).to(device)\n",
        "#model = torch.nn.parallel.DataParallel(model, device_ids=DEVICE_IDS)\n",
        "display(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "net(\n",
              "  (net): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Dropout(p=0.2, inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): Dropout(p=0.2, inplace=True)\n",
              "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (21): Dropout(p=0.2, inplace=True)\n",
              "    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=True)\n",
              "    (1): Linear(in_features=9216, out_features=512, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=True)\n",
              "    (4): Linear(in_features=512, out_features=7, bias=True)\n",
              "    (5): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxt6Gzba0vwf"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2byeJwx0yvy"
      },
      "source": [
        "\n",
        "# Parameters \n",
        "in_features = 256*7*7\n",
        "out_categories = 7\n",
        "layer_1 = 256\n",
        "layer_2 = 256\n",
        "# Build classifier\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    ('dropout1', nn.Dropout(0.5)),\n",
        "    ('fc1', nn.Linear(in_features, layer_1)),\n",
        "    ('relu', nn.ReLU(True)),\n",
        "    ('dropout2', nn.Dropout(0.5)),\n",
        "    ('fc2', nn.Linear(layer_1, layer_2)),\n",
        "    ('relu', nn.ReLU(True)),\n",
        "    ('dropout3', nn.Dropout(0.5)),    \n",
        "    ('fc3', nn.Linear(layer_2, out_categories)),\n",
        "    ('output', nn.LogSoftmax(dim=1))\n",
        "    ]))\n",
        "\n",
        "# Assign new classifier to VGG-11 architecture \n",
        "model.classifier = classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSFJnEEk01dr",
        "outputId": "bf269d71-9d70-4aa6-eb6b-f4d41caf0ebf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# Instantiate loss function\n",
        "loss_function = nn.NLLLoss()\n",
        "\n",
        "# Instantiate optimization algorithm \n",
        "learning_rate = 1e-4\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# Enable CUDA: use GPUs for model computation\n",
        "if torch.cuda.is_available():\n",
        "    print('a')\n",
        "    model.to('cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr7TBOzb1BEI"
      },
      "source": [
        "# Epochs: number of iterations over the entire training dataset\n",
        "epochs = 40\n",
        "# Number of iterations between printing loss and accuracy \n",
        "print_steps = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ER3bI178MGg",
        "outputId": "fcae54ce-53c0-4cdd-db7f-deee254bd313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,832,007 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLttiVIutXW1",
        "outputId": "18205dd7-ff7d-441f-cb8d-989dd1eb0695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "net(\n",
              "  (net): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Dropout(p=0.2, inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): ReLU(inplace=True)\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): Dropout(p=0.2, inplace=True)\n",
              "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (18): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (21): Dropout(p=0.2, inplace=True)\n",
              "    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (dropout1): Dropout(p=0.5, inplace=False)\n",
              "    (fc1): Linear(in_features=12544, out_features=256, bias=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (dropout2): Dropout(p=0.5, inplace=False)\n",
              "    (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
              "    (dropout3): Dropout(p=0.5, inplace=False)\n",
              "    (fc3): Linear(in_features=256, out_features=7, bias=True)\n",
              "    (output): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUr1RKmESlUh",
        "outputId": "82d4c5b9-9560-4139-bcec-25f4e72d4fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,832,007 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sPtOJLb5WVw"
      },
      "source": [
        "# Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAZujqh-5V1H"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename = \"checkpointcrazy9.pth.tar\"):\n",
        "    if is_best:\n",
        "        best_accuracy = state['best_accuracy']\n",
        "        print (\"=> Saving a new best with {:.4}% validation accuracy\".format(100 * best_accuracy.numpy()[0]))\n",
        "        torch.save(state, filename)  # save checkpoint\n",
        "    else:\n",
        "        print (\"=> Validation Accuracy did not improve\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ox5S30c5ZY2",
        "outputId": "9d326479-1b64-470f-d9e8-0108473ad825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "if os.path.isfile(resume_weights):\n",
        "    print(\"=> loading checkpoint '{}' ...\".format(resume_weights))\n",
        "    if torch.cuda:\n",
        "        checkpoint = torch.load(resume_weights)\n",
        "    else:\n",
        "       checkpoint = torch.load(resume_weights,\n",
        "                               map_location=lambda storage,\n",
        "                               loc: storage)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_accuracy = checkpoint['best_accuracy']\n",
        "    print('=> loaded checkpoint {} (trained for {} epochs) with {:.4}% validation accuracy'.format(resume_weights,\n",
        "        checkpoint['epoch'],100 * best_accuracy.numpy()[0]))\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "else:print(\"no\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint 'checkpointcrazy9.pth.tar' ...\n",
            "=> loaded checkpoint checkpointcrazy9.pth.tar (trained for 40 epochs) with 75.0% validation accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0elE66t5psv"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUPFUOUQ1DJ9"
      },
      "source": [
        "%%time\n",
        "\n",
        "# Initialize steps\n",
        "step = 0\n",
        "\n",
        "# Iterate over number of epochs\n",
        "for e in range(epochs):\n",
        "    running_loss = 0 \n",
        "\n",
        "    # Iterate over the entire training dataset\n",
        "    # one batch per iteration \n",
        "    for input_images, labels in folderloader:\n",
        "        step += 1     \n",
        "        \n",
        "        # Enable CUDA: use GPUs for model computation\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = input_images.to('cuda'), labels.to('cuda')   \n",
        "        else:\n",
        "            inputs, labels = input_images, labels\n",
        "        \n",
        "        # Clear the gradients of all optimized tensors\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model.forward(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "     \n",
        "        #print(predicted,labels)\n",
        "        validation_correct = 0\n",
        "        validation_total = 0\n",
        "\n",
        "        training_correct = 0\n",
        "        training_total = 0        \n",
        "\n",
        "        # no_grad() prevents tracking history (and using memory)\n",
        "        with torch.no_grad(): \n",
        "            \n",
        "            # Iterate over the entire validation dataset\n",
        "            for input_images3, labels3 in folderloader:\n",
        "                \n",
        "                # Enable CUDA: use GPUs for model computation\n",
        "                if torch.cuda.is_available():\n",
        "                    input_images3, labels3 = input_images3.to('cuda'), labels3.to('cuda')\n",
        "                \n",
        "                # Make predictions \n",
        "                outputs3 = model(input_images3)\n",
        "                _, predicted3 = torch.max(outputs3.data, 1)\n",
        "                #print(predicted2,labels2)\n",
        "                \n",
        "                # Count total and correct predictions\n",
        "                training_total += labels3.size(0)\n",
        "                training_correct += (predicted3 == labels3).sum().item()   \n",
        "\n",
        "        with torch.no_grad(): \n",
        "            \n",
        "            # Iterate over the entire validation dataset\n",
        "            for input_images2, labels2 in folderloader_valid:\n",
        "                \n",
        "                # Enable CUDA: use GPUs for model computation\n",
        "                if torch.cuda.is_available():\n",
        "                    input_images2, labels2 = input_images2.to('cuda'), labels2.to('cuda')\n",
        "                \n",
        "                # Make predictions \n",
        "                outputs2 = model(input_images2)\n",
        "                _, predicted2 = torch.max(outputs2.data, 1)\n",
        "                #print(predicted2,labels2)\n",
        "                \n",
        "                # Count total and correct predictions\n",
        "                validation_total += labels2.size(0)\n",
        "                validation_correct += (predicted2 == labels2).sum().item()\n",
        "        loss = loss_function(outputs, labels)\n",
        "        val_acc = validation_correct / validation_total\n",
        "        train_acc = training_correct / training_total\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Calculate and print running training loss\n",
        "        running_loss += loss.item()       \n",
        "        if step % print_steps == 0:\n",
        "            print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
        "                  \"| Loss: {:.4f}\".format(running_loss/print_steps),\n",
        "                  \"| Val Acc: {:.4f}\".format(val_acc),\n",
        "                  \"| Train Acc: {:.4f}\".format(train_acc),)\n",
        "            running_loss = 0\n",
        "    acc1 = torch.FloatTensor([val_acc])\n",
        "    is_best = bool(acc1.numpy() > best_accuracy.numpy())\n",
        "    best_accuracy = torch.FloatTensor(max(acc1.numpy(), best_accuracy.numpy()))\n",
        "    save_checkpoint({\n",
        "        'epoch' : start_epoch + epochs,\n",
        "        'state_dict' : model.state_dict(),\n",
        "        'best_accuracy' : best_accuracy\n",
        "        }, is_best)\n",
        "        \n",
        "print('\\nCount of data batches seen:  {} \\n'.format(step))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GeclCPrhD5u"
      },
      "source": [
        "# Validation and Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVnidypMdk7X",
        "outputId": "3803632a-3cc0-4b48-dc48-5f2d41727b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "if os.path.isfile(resume_weights):\n",
        "    print(\"=> loading checkpoint '{}' ...\".format(resume_weights))\n",
        "    if torch.cuda:\n",
        "        checkpoint = torch.load(resume_weights)\n",
        "    else:\n",
        "       checkpoint = torch.load(resume_weights,\n",
        "                               map_location=lambda storage,\n",
        "                               loc: storage)\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_accuracy = checkpoint['best_accuracy']\n",
        "    print('=> loaded checkpoint {} (trained for {} epochs) with {:.4}% validation accuracy'.format(resume_weights,\n",
        "        checkpoint['epoch'],100 * best_accuracy.numpy()[0]))\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "else:print(\"no\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint 'checkpointcrazy9.pth.tar' ...\n",
            "=> loaded checkpoint checkpointcrazy9.pth.tar (trained for 40 epochs) with 75.0% validation accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZSKvM6B1HAR",
        "outputId": "b2ae8d15-5188-4b6c-e246-a40bbbc9ad5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "validation_correct = 0\n",
        "validation_total = 0\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "# no_grad() prevents tracking history (and using memory)\n",
        "model.eval()\n",
        "with torch.no_grad(): \n",
        "    \n",
        "    # Iterate over the entire validation dataset\n",
        "    for input_images, labels in folderloader_valid:\n",
        "        \n",
        "        # Enable CUDA: use GPUs for model computation\n",
        "        if torch.cuda.is_available():\n",
        "            input_images, labels = input_images.to('cuda'), labels.to('cuda')\n",
        "        \n",
        "        # Make predictions \n",
        "        outputs = model(input_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        print(input_images.size(),labels)\n",
        "        \n",
        "        # Count total and correct predictions\n",
        "        validation_total += labels.size(0)\n",
        "        validation_correct += (predicted == labels).sum().item()\n",
        "# Print validation accuracy\n",
        "print('Validation accuracy ({0:d} validation images): {1:.1%}'\n",
        "      .format(validation_total, validation_correct / validation_total))        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 256, 256]) tensor([0, 5, 3, 0, 1, 4, 6, 4, 1, 6, 3, 5, 2, 6, 1, 1, 1, 4, 6, 1, 6, 6, 3, 3,\n",
            "        0, 1, 6, 2, 5, 4, 1, 3], device='cuda:0')\n",
            "torch.Size([32, 3, 256, 256]) tensor([1, 6, 1, 2, 4, 4, 1, 5, 6, 0, 4, 2, 0, 4, 2, 1, 2, 5, 4, 1, 5, 4, 2, 1,\n",
            "        0, 4, 2, 3, 0, 0, 6, 2], device='cuda:0')\n",
            "torch.Size([32, 3, 256, 256]) tensor([6, 1, 2, 4, 3, 1, 2, 6, 5, 2, 0, 4, 2, 0, 3, 5, 0, 6, 1, 0, 1, 0, 4, 0,\n",
            "        6, 2, 3, 0, 1, 3, 6, 0], device='cuda:0')\n",
            "torch.Size([16, 3, 256, 256]) tensor([1, 0, 6, 0, 4, 0, 6, 3, 6, 2, 5, 3, 2, 3, 4, 1], device='cuda:0')\n",
            "Validation accuracy (112 validation images): 80.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMWRtqSEym1L",
        "outputId": "781d9090-d110-457d-e4e0-d42dcb43971a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "import glob\n",
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path\n",
        "\n",
        "data_dir = \"/content/drive/My Drive/IITB Sem5/GNR 638/kaggle/test_set\"\n",
        "dataFromFolders_test = ImageFolderWithPaths(root=dir_test,transform = test_transform)\n",
        "folderloader_test = DataLoader(dataFromFolders_test,batch_size=1)\n",
        "model.eval()\n",
        "final=[]\n",
        "with torch.no_grad(): \n",
        "    for input_images, labels, paths in folderloader_test:\n",
        "        if torch.cuda.is_available():\n",
        "            input_images, labels = input_images.to('cuda'), labels.to('cuda')\n",
        "\n",
        "        outputs = model(input_images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        final.append(predicted.cpu().numpy()[0])\n",
        "\n",
        "my_dict = {0:1, 1:2, 2:3, 3:7, 4:4, 5:6, 6:5}\n",
        "answers = np.vectorize(my_dict.get)(final).tolist()\n",
        "answers = [str(x).strip(' ') for x in answers]\n",
        "answers = list(map(int, answers)) \n",
        "#print(answers)\n",
        "mypath = dir_test\n",
        "fileslist = []\n",
        "for root, directories, files in os.walk(mypath, topdown=False):\n",
        "    #print(files)\n",
        "    for name in files:\n",
        "        #print(name);\n",
        "        if name[4:] == '.jpg':\n",
        "            fileslist.append(int(name[:4]))\n",
        "fileslist = np.sort(fileslist)\n",
        "#print(fileslist)\n",
        "arr1 = np.array(fileslist)\n",
        "arr2 = np.array(answers)\n",
        "b = np.stack((arr1,arr2), axis=1)\n",
        "\n",
        "b = [[x for x in y if x != ''] for y in b]\n",
        "print(b)\n",
        "np.savetxt(\"18010088.csv\", b, delimiter=',', header=\"ImageID,Label\", fmt='%1d',comments='')\n",
        "# 1 - Basketball court 2 - Beach 3 - Forest 4 - Railway \n",
        "# 5 - Tennis court 6 - Water pool 7 - Others      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1001, 5], [1002, 7], [1003, 6], [1004, 3], [1005, 5], [1006, 2], [1007, 6], [1008, 4], [1009, 4], [1010, 6], [1011, 6], [1012, 6], [1013, 2], [1014, 7], [1015, 6], [1016, 5], [1017, 6], [1018, 7], [1019, 3], [1020, 7], [1021, 7], [1022, 6], [1023, 4], [1024, 7], [1025, 7], [1026, 6], [1027, 6], [1028, 7], [1029, 6], [1030, 3], [1031, 6], [1032, 7], [1033, 4], [1034, 7], [1035, 5], [1036, 4], [1037, 4], [1038, 2], [1039, 5], [1040, 1], [1041, 6], [1042, 7], [1043, 6], [1044, 4], [1045, 7], [1046, 6], [1047, 7], [1048, 5], [1049, 3], [1050, 7], [1051, 7], [1052, 3], [1053, 3], [1054, 6], [1055, 4], [1056, 3], [1057, 4], [1058, 4], [1059, 7], [1060, 5], [1061, 7], [1062, 4], [1063, 3], [1064, 6], [1065, 7], [1066, 7], [1067, 7], [1068, 5], [1069, 7], [1070, 3], [1071, 3], [1072, 3], [1073, 7], [1074, 1], [1075, 3], [1076, 6], [1077, 6], [1078, 7], [1079, 3], [1080, 4], [1081, 6], [1082, 6], [1083, 6], [1084, 3], [1085, 7], [1086, 7], [1087, 5], [1088, 3], [1089, 3], [1090, 7], [1091, 4], [1092, 7], [1093, 6], [1094, 4], [1095, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}